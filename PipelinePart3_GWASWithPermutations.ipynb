{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLANATION\n",
    "This script performs GWAS on a pre-selected number of variants (in Plink binary format) and on a specific phenotype you want. Ideally, the phenotype has been adjusted for inversions, infection, and also log-transformed if the raw phenotype's errors weren't normally distributed.\n",
    "\n",
    "BEWARE: You should format your phenotype line IDs in the same way as denoted in the .fam variant file you are feeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Time measurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.clock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSTANTS and INPUTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 0.331671272727\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Inputs/GWAS_Constants.txt', header=None)\n",
    "\n",
    "NUMBER_OF_PERMUTATIONS = int(data[0][0])\n",
    "OUTPUT_NAME = data[0][1]\n",
    "PHENOTYPE_DATA = data[0][2]\n",
    "VARIANTS_TO_TEST = data[0][3]\n",
    "USE_OFFICIAL_GSM = data[0][4]\n",
    "if USE_OFFICIAL_GSM == \"TRUE\":\n",
    "    USE_OFFICIAL_GSM = True\n",
    "else:\n",
    "    USE_OFFICIAL_GSM = False\n",
    "    \n",
    "    \n",
    "print 'Time (s): ' + str(time.clock()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing, general preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 1.48057939394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from fastlmm.association import single_snp\n",
    "from fastlmm.inference.fastlmm_predictor import _snps_fixup, _pheno_fixup, _kernel_fixup, _SnpTrainTest\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "# We're going to need PySnpTools, to do permutations, because we can shuffle bed files by varint using Bed\n",
    "import sys\n",
    "sys.path.append('../PySnpTools')\n",
    "from pysnptools.snpreader import Bed\n",
    "from shutil import copyfile\n",
    "\n",
    "print 'Time (s): ' + str(time.clock()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\pysnptools-0.3.13-py2.7-win-amd64.egg\\pysnptools\\snpreader\\bed.py:42: FutureWarning: 'count_A1' was not set. For now it will default to 'False', but in the future it will default to 'True'\n",
      "  warnings.warn(\"'count_A1' was not set. For now it will default to 'False', but in the future it will default to 'True'\", FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\pysnptools-0.3.13-py2.7-win-amd64.egg\\pysnptools\\snpreader\\snpreader.py:625: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.string_ == np.dtype(str).type`.\n",
      "  assert np.issubdtype(self._row.dtype, str) and len(self._row.shape)==2 and self._row.shape[1]==2, \"iid should be dtype str, have two dimensions, and the second dimension should be size 2\"\n",
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\pysnptools-0.3.13-py2.7-win-amd64.egg\\pysnptools\\snpreader\\snpreader.py:626: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.string_ == np.dtype(str).type`.\n",
      "  assert np.issubdtype(self._col.dtype, str) and len(self._col.shape)==1, \"sid should be of dtype of str and one dimensional\"\n",
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\pysnptools-0.3.13-py2.7-win-amd64.egg\\pysnptools\\snpreader\\snpreader.py:676: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  pos = fields.as_matrix([0,2,3])\n",
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\pysnptools-0.3.13-py2.7-win-amd64.egg\\pysnptools\\kernelreader\\kernelreader.py:325: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.string_ == np.dtype(str).type`.\n",
      "  assert np.issubdtype(self._row.dtype, str) and len(self._row.shape)==2 and self._row.shape[1]==2, \"iid0 should be dtype str, have two dimensions, and the second dimension should be size 2\"\n",
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\pysnptools-0.3.13-py2.7-win-amd64.egg\\pysnptools\\kernelreader\\kernelreader.py:326: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.string_ == np.dtype(str).type`.\n",
      "  assert np.issubdtype(self._col.dtype, str) and len(self._col.shape)==2 and self._col.shape[1]==2, \"iid1 should be dtype str, have two dimensions, and the second dimension should be size 2\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time (s): 67.186918303\n"
     ]
    }
   ],
   "source": [
    "# Clearing cache\n",
    "# This ensures that the relationship matrix is recalculated for each phenotype.\n",
    "try:\n",
    "    os.remove('Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache.npz')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "# Performing GWAS on the real phenotype:\n",
    "\n",
    "if USE_OFFICIAL_GSM == False:\n",
    "    results_df = single_snp(VARIANTS_TO_TEST,  PHENOTYPE_DATA,\n",
    "                            cache_file='Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache.npz',\n",
    "                            leave_out_one_chrom=False,\n",
    "                            save_test_statistic=True,\n",
    "                            output_file_name = 'Outputs/' + OUTPUT_NAME + '_Original.txt',\n",
    "                            )\n",
    "else:\n",
    "    \n",
    "    # First, constructing GSM form official relationship matrix (GSM):\n",
    "    import re\n",
    "    import sys\n",
    "    from pysnptools.kernelreader import KernelData\n",
    "\n",
    "    with open('Raw_Data/freeze2.common.rel.mat') as f:\n",
    "        first_line = f.readline()\n",
    "\n",
    "\n",
    "    tmp = re.split(r'\\t+', first_line.rstrip())\n",
    "    tmp = tmp[1:]\n",
    "    # print tmp\n",
    "    iids = []\n",
    "    for i in range(len(tmp)):\n",
    "         iids.append(re.split(r' +', tmp[i]))\n",
    "\n",
    "    Gsm = np.genfromtxt('Raw_Data/freeze2.common.rel.mat', skip_header=True)\n",
    "    # print Gsm\n",
    "\n",
    "    Gsm = Gsm[:, 2:207]\n",
    "    # Gsm = LMM(K=Gsm)\n",
    "    # Gsm.setSU_fromK()\n",
    "    # Gsm.K\n",
    "\n",
    "    # np.savetxt('../Inputs/NCSU_GSM_U.txt', Gsm.U)\n",
    "    # np.savetxt('../Inputs/NCSU_GSM_S.txt', Gsm.S)\n",
    "    \n",
    "    my_kernel = KernelData(iid=iids, val=Gsm.tolist())\n",
    "    \n",
    "    # Now, performing GSM using the official GSM as kernel:\n",
    "    results_df = single_snp(VARIANTS_TO_TEST,\n",
    "                            PHENOTYPE_DATA,\n",
    "                            K0=my_kernel,\n",
    "                            leave_out_one_chrom=False,\n",
    "                            save_test_statistic=True,\n",
    "                            output_file_name = 'Outputs/' + OUTPUT_NAME + '_Original.txt',\n",
    "                            )\n",
    "\n",
    "print 'Total Time (s): ' + str(time.clock()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s): 68.8176252121\n"
     ]
    }
   ],
   "source": [
    "test_stat = pd.read_csv('Outputs/Fast-Lmm-Cache/Test-Stat-Cache.txt', header=None)\n",
    "test_stat = test_stat.replace('[\\[\\] ]', '', regex=True)\n",
    "test_stat = pd.to_numeric(test_stat[0])\n",
    "\n",
    "results_df['Full ID'] = results_df['Chr'].astype('str') + '_' + results_df['ChrPos'].astype('str')\n",
    "results_df = pd.concat([results_df[['Chr', 'ChrPos', 'SNP', 'Full ID', 'PValue']], test_stat],\n",
    "                       axis = 1)\n",
    "results_df.columns = ['Chr', 'ChrPos', 'SNP', 'Full ID', 'PValue', 'F-test statistic']\n",
    "\n",
    "mybed = Bed(VARIANTS_TO_TEST + '.bed')\n",
    "mysnpdata = mybed.read()\n",
    "\n",
    "print 'Time (s): ' + str(time.clock()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = _pheno_fixup(PHENOTYPE_DATA, count_A1=None).read()\n",
    "pheno = pheno.val[np.searchsorted(pheno.iid[:,1], mysnpdata.iid[:,1])]\n",
    "snpdata = mysnpdata.val\n",
    "diff = range(snpdata.shape[1])\n",
    "maf = range(snpdata.shape[1])\n",
    "n_alleles = range(snpdata.shape[1])\n",
    "mean_major = range(snpdata.shape[1])\n",
    "for i in range(snpdata.shape[1]):\n",
    "    ref = [j for j, x in enumerate(snpdata[:,i]) if x == 2]\n",
    "    alt = [j for j, x in enumerate(snpdata[:,i]) if x == 0]\n",
    "    meanref = np.mean(pheno[ref])\n",
    "    meanalt = np.mean(pheno[alt])\n",
    "    if len(ref) > len(alt):\n",
    "        diff[i] = meanref - meanalt\n",
    "        maf[i] = float(len(alt)) / (len(ref) + len(alt))\n",
    "        n_alleles[i] = len(ref) + len(alt)\n",
    "        mean_major[i] = meanref\n",
    "    elif len(ref) + len(alt) == 0:\n",
    "        diff[i] = float('NaN')\n",
    "        maf[i] = float('NaN')\n",
    "        n_alleles[i] = len(ref) + len(alt)\n",
    "        mean_major[i] = float('NaN')\n",
    "    else:\n",
    "        diff[i] = meanalt - meanref\n",
    "        maf[i] = float(len(ref)) / (len(ref) + len(alt))\n",
    "        n_alleles[i] = len(ref) + len(alt)\n",
    "        mean_major[i] = meanalt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = diff_df = pd.DataFrame(data={'MajMinDiff':diff,\n",
    "                                       'MeanMajor': mean_major,\n",
    "                                       'MAF':maf,\n",
    "                                       'NAlleles':n_alleles})\n",
    "diff_df['SNP'] = mysnpdata.sid\n",
    "results_df = pd.merge(results_df, diff_df, on='SNP')\n",
    "    \n",
    "\n",
    "# PHENOTYPE shuffling/permutation and adding the p-values from the resulting\n",
    "# GWAS to the results data frame.\n",
    "#phenotype_to_shuffle = pd.read_table(PHENOTYPE_DATA,\n",
    "#                                     sep=' ', header=None)\n",
    "#indices = range(len(phenotype_to_shuffle))\n",
    "#temp_shuffled_pheno = '../Outputs/Fast-Lmm-Inputs/Temporary-Shuffled-Phenotype.txt'\n",
    "#\n",
    "#for i in range(NUMBER_OF_PERMUTATIONS):\n",
    "#    time_permut_0 = time.time()\n",
    "#    shuffle(indices)\n",
    "#    phenotype_shuffled = []\n",
    "#    for j in range(len(indices)):\n",
    "#        phenotype_shuffled.append(phenotype_to_shuffle[2][indices[j]])\n",
    "#    \n",
    "#    phenotype_to_shuffle[2] = phenotype_shuffled\n",
    "#    phenotype_to_shuffle.to_csv(temp_shuffled_pheno, header=False, index=False, sep=' ')\n",
    "#    tmp_shuffled_df = single_snp(VARIANTS_TO_TEST,  temp_shuffled_pheno,\n",
    "##                                cache_file='../Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache'+str(i)\n",
    "#                                 cache_file='../Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache.npz',\n",
    "#                                 leave_out_one_chrom=False,\n",
    "#                                 )\n",
    "#    tmp_shuffled_df['Full ID'] = tmp_shuffled_df['Chr'].astype('str') + '_' + tmp_shuffled_df['ChrPos'].astype('str')\n",
    "#    \n",
    "#    # sorting the new df to match the original\n",
    "#    tmp_shuffled_df = tmp_shuffled_df[['Full ID', 'PValue']]\n",
    "#    tmp_shuffled_df['PValue'].rename('PValueShuffled'+str(i+1))\n",
    "#    \n",
    "#    \n",
    "#    results_df = pd.merge(results_df, tmp_shuffled_df, on='Full ID')\n",
    "#    print('Time for permutation GWAS:' + str(time.time() - time_permut_0) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling ALLELES by VARIANT\n",
    "\n",
    "for i in range(NUMBER_OF_PERMUTATIONS):\n",
    "    time_permut_0 = time.time()\n",
    "    \n",
    "    # Python works a little different than R: Shuffle directly modifies the input data frame!\n",
    "    np.random.shuffle(mysnpdata.val)\n",
    "    Bed.write('VariantsPermuted', mysnpdata)\n",
    "    copyfile(VARIANTS_TO_TEST + '.bim', 'VariantsPermuted.bim')\n",
    "\n",
    "    tmp_shuffled_df = single_snp('VariantsPermuted',  PHENOTYPE_DATA,\n",
    "#                                cache_file='Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache'+str(i)\n",
    "                                 cache_file='Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache.npz',\n",
    "                                 leave_out_one_chrom=False,\n",
    "                                 )\n",
    "    tmp_shuffled_df['Full ID'] = tmp_shuffled_df['Chr'].astype('str') + '_' + tmp_shuffled_df['ChrPos'].astype('str')\n",
    "    \n",
    "    # sorting the new df to match the original\n",
    "    tmp_shuffled_df = tmp_shuffled_df[['Full ID', 'SNP', 'PValue']]\n",
    "    tmp_shuffled_df = tmp_shuffled_df.rename(columns={'Full ID':'Full IDShuffled'+str(i+1),\n",
    "                                                      'PValue':'PValueShuffled'+str(i+1)})\n",
    "    \n",
    "    snpdata = mysnpdata.val\n",
    "    diff = range(snpdata.shape[1])\n",
    "    maf = range(snpdata.shape[1])\n",
    "    n_alleles = range(snpdata.shape[1])\n",
    "    mean_major = range(snpdata.shape[1])\n",
    "    for k in range(snpdata.shape[1]):\n",
    "        ref = [j for j, x in enumerate(snpdata[:,k]) if x == 2]\n",
    "        alt = [j for j, x in enumerate(snpdata[:,k]) if x == 0]\n",
    "        meanref = np.mean(pheno[ref])\n",
    "        meanalt = np.mean(pheno[alt])\n",
    "        if len(ref) > len(alt):\n",
    "            diff[k] = meanref - meanalt\n",
    "            maf[k] = float(len(alt)) / (len(ref) + len(alt))\n",
    "            n_alleles[k] = len(ref) + len(alt)\n",
    "            mean_major[k] = meanref\n",
    "        elif len(ref) + len(alt) == 0:\n",
    "            diff[k] = float('NaN')\n",
    "            maf[k] = float('NaN')\n",
    "            n_alleles[k] = len(ref) + len(alt)\n",
    "            mean_major[k] = float('NaN')\n",
    "        else:\n",
    "            diff[k] = meanalt - meanref\n",
    "            maf[k] = float(len(ref)) / (len(ref) + len(alt))\n",
    "            n_alleles[k] = len(ref) + len(alt)\n",
    "            mean_major[k] = meanalt\n",
    "        \n",
    "    diff_df = diff_df = pd.DataFrame(data={'MajMinDiffShuffled'+str(i+1):diff,\n",
    "                                           'MeanMajorShuffled'+str(i+1): mean_major,\n",
    "                                           'NAllelesShuffled'+str(i+1):n_alleles,\n",
    "                                           'MAFShuffled'+str(i+1):maf})\n",
    "    diff_df['SNP'] = mysnpdata.sid\n",
    "    tmp_shuffled_df = pd.merge(tmp_shuffled_df, diff_df, on='SNP')\n",
    "    tmp_shuffled_df = tmp_shuffled_df.rename(columns={'SNP':'SNPShuffled'+str(i+1)})\n",
    "    \n",
    "#    results_df = pd.merge(results_df, tmp_shuffled_df, on='Full ID')\n",
    "    results_df = results_df.join(tmp_shuffled_df)\n",
    "    print('Time for permutation GWAS:' + str(time.time() - time_permut_0) + 's')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(OUTPUT_NAME + '_with_Permutations.txt', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manhattan Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# makes sure can save pictures that a display is present!\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "import pylab\n",
    "import fastlmm.util.util as flutil\n",
    "\n",
    "# better manhattan plot than MS Genomics one (or at least more robust)\n",
    "# can be tweaked at will!\n",
    "from assocplots.manhattan import *\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "figure(num=None, figsize=(10, 7), dpi=80,)\n",
    "\n",
    "manhattan(results_df[\"PValue\"], results_df[\"ChrPos\"], results_df[\"Chr\"], OUTPUT_NAME,\n",
    "         lines=[5], colors=['r', 'b'], cut=1)\n",
    "\n",
    "plt.savefig('Figures/' + OUTPUT_NAME + '_Manhattan_Plot.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QQ Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\fastlmm-0.2.31-py2.7-win-amd64.egg\\fastlmm\\feature_selection\\PerformSelectionDistributable.py:13: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\tornado\\ioloop.py\", line 1008, in start\n",
      "    self._run_callback(self._callbacks.popleft())\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\tornado\\ioloop.py\", line 759, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2724, in run_cell\n",
      "    self.events.trigger('post_run_cell')\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\IPython\\core\\events.py\", line 74, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\", line 160, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\IPython\\core\\pylabtools.py\", line 315, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\matplotlib\\pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\matplotlib\\__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg') #This lets it work even on machines without graphics displays\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.9961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\numpy\\lib\\scimath.py:120: RuntimeWarning: invalid value encountered in less\n",
      "  if any(isreal(x) & (x < 0)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time after QQ plot: 108.641943273\n"
     ]
    }
   ],
   "source": [
    "from fastlmm.util.stats import plotp\n",
    "plotp.qqplot(results_df[\"PValue\"].values, xlim=[0,5], ylim=[0,5])\n",
    "pylab.savefig('Figures/' + OUTPUT_NAME + 'QQ_Plot.png')\n",
    "pylab.close()\n",
    "\n",
    "print 'Time after QQ plot: ' + str(time.clock()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\\nDone!\\n\\n\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
