{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\micha\\\\Desktop\\\\MastersProject\\\\Fast-Lmm'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\pysnptools-0.3.13-py2.7-win-amd64.egg\\pysnptools\\snpreader\\bed.py:42: FutureWarning: 'count_A1' was not set. For now it will default to 'False', but in the future it will default to 'True'\n",
      "  warnings.warn(\"'count_A1' was not set. For now it will default to 'False', but in the future it will default to 'True'\", FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\pysnptools-0.3.13-py2.7-win-amd64.egg\\pysnptools\\snpreader\\snpreader.py:625: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.string_ == np.dtype(str).type`.\n",
      "  assert np.issubdtype(self._row.dtype, str) and len(self._row.shape)==2 and self._row.shape[1]==2, \"iid should be dtype str, have two dimensions, and the second dimension should be size 2\"\n",
      "C:\\Users\\micha\\Anaconda2\\lib\\site-packages\\pysnptools-0.3.13-py2.7-win-amd64.egg\\pysnptools\\snpreader\\snpreader.py:626: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.string_ == np.dtype(str).type`.\n",
      "  assert np.issubdtype(self._col.dtype, str) and len(self._col.shape)==1, \"sid should be of dtype of str and one dimensional\"\n"
     ]
    }
   ],
   "source": [
    "from fastlmm.association import single_snp\n",
    "from fastlmm.inference.fastlmm_predictor import _snps_fixup, _pheno_fixup, _kernel_fixup, _SnpTrainTest\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "# We're going to need PySnpTools, to do permutations, because we can shuffle bed files by varint using Bed\n",
    "import sys\n",
    "sys.path.append('../PySnpTools')\n",
    "from pysnptools.snpreader import Bed\n",
    "from shutil import copyfile\n",
    "\n",
    "# EXPLANATION =================================================================\n",
    "\n",
    "# This script performs GWAS on a pre-selected number of variants (in Plink\n",
    "# binary format) and on a specific phenotype you want. Ideally, the phenotype\n",
    "# has been adjusted for inversions, infection, and also log-transformed\n",
    "# if the raw phenotype wasn't deemed normally distributed.\n",
    "\n",
    "# BEWARE: You should format your phenotype line IDs in the same way as denoted\n",
    "# in the .fam variant file you are using.\n",
    "\n",
    "\n",
    "# CONSTANTS ===================================================================\n",
    "\n",
    "# Permutation info\n",
    "NUMBER_OF_PERMUTATIONS = 0\n",
    "# Where you want to save your phenotype\n",
    "OUTPUT_NAME = '../Outputs/GWASMay'\n",
    "\n",
    "\n",
    "# INPUTS ======================================================================\n",
    "\n",
    "# Phenotype data to test\n",
    "#phenotype_data = '../Outputs/Fast-Lmm-Inputs/Fast-Lmm-Input-Interocular-Distance-Vonesch2016-Female.txt'\n",
    "phenotype_data = '../Outputs/Fast-Lmm-Inputs/Fast-Lmm-Input-MassFemaleOnline.txt'\n",
    "#phenotype_data = '../Outputs/Fast-Lmm-Inputs/Dgrp2-AllLines-RandomPheno-for-Mito.txt'\n",
    "#phenotype_data = '../Outputs/Fast-Lmm-Inputs/T5-Pheno-for-Fast-Lmm-DGRPFormat.txt'\n",
    "#phenotype_data = '../Outputs/Fast-Lmm-Inputs/T5-Pheno-for-Fast-Lmm.txt'\n",
    "\n",
    "\n",
    "# Variants to test your phenotype on\n",
    "#variants_to_test = '../Outputs/Plinkfiles/MitoSeq_AllRuns_dm6_chrM.annot.biallellic_ConvertedReference'\n",
    "#variants_to_test = '../Data/dgrp2'\n",
    "#variants_to_test = '../Outputs/Plinkfiles/DGRP2Chr2R'\n",
    "variants_to_test = '../Outputs/Plinkfiles/Dgrp2-MassLines-Maf5'\n",
    "#variants_to_test = '../Outputs/Plinkfiles/Dgrp2-CSLines-Maf5'\n",
    "\n",
    "\n",
    "# ACTUAL GWAS =================================================================\n",
    "\n",
    "# Clearing cache\n",
    "# This ensures that the relationship matrix is recalculated for each phenotype.\n",
    "try:\n",
    "    os.remove('../Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache.npz')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "# Performing GWAS on the real phenotype:\n",
    "\n",
    "time_0 = time.time()\n",
    "results_df = single_snp(variants_to_test,  phenotype_data,\n",
    "                        cache_file='../Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache.npz',\n",
    "                        leave_out_one_chrom=False,\n",
    "                        save_test_statistic=True,\n",
    "                        output_file_name = OUTPUT_NAME + '-Original.txt',\n",
    "                        )\n",
    "time_1 = time.time()\n",
    "\n",
    "print('Time for full GWAS:' + str(time_1 - time_0) + 's')\n",
    "\n",
    "test_stat = pd.read_csv('../Outputs/Fast-Lmm-Cache/Test-Stat-Cache.txt', header=None)\n",
    "test_stat = test_stat.replace('[\\[\\] ]', '', regex=True)\n",
    "test_stat = pd.to_numeric(test_stat[0])\n",
    "\n",
    "results_df['Full ID'] = results_df['Chr'].astype('str') + '_' + results_df['ChrPos'].astype('str')\n",
    "results_df = pd.concat([results_df[['Chr', 'ChrPos', 'SNP', 'Full ID', 'PValue']], test_stat],\n",
    "                       axis = 1)\n",
    "results_df.columns = ['Chr', 'ChrPos', 'SNP', 'Full ID', 'PValue', 'F-test statistic']\n",
    "\n",
    "mybed = Bed(variants_to_test + '.bed')\n",
    "mysnpdata = mybed.read()\n",
    "\n",
    "pheno = _pheno_fixup(phenotype_data, count_A1=None).read()\n",
    "pheno = pheno.val[np.searchsorted(pheno.iid[:,1], mysnpdata.iid[:,1])]\n",
    "snpdata = mysnpdata.val\n",
    "diff = range(snpdata.shape[1])\n",
    "maf = range(snpdata.shape[1])\n",
    "n_alleles = range(snpdata.shape[1])\n",
    "mean_major = range(snpdata.shape[1])\n",
    "for i in range(snpdata.shape[1]):\n",
    "    ref = [j for j, x in enumerate(snpdata[:,i]) if x == 2]\n",
    "    alt = [j for j, x in enumerate(snpdata[:,i]) if x == 0]\n",
    "    meanref = np.mean(pheno[ref])\n",
    "    meanalt = np.mean(pheno[alt])\n",
    "    if len(ref) > len(alt):\n",
    "        diff[i] = meanref - meanalt\n",
    "        maf[i] = float(len(alt)) / (len(ref) + len(alt))\n",
    "        n_alleles[i] = len(ref) + len(alt)\n",
    "        mean_major[i] = meanref\n",
    "    elif len(ref) + len(alt) == 0:\n",
    "        diff[i] = float('NaN')\n",
    "        maf[i] = float('NaN')\n",
    "        n_alleles[i] = len(ref) + len(alt)\n",
    "        mean_major[i] = float('NaN')\n",
    "    else:\n",
    "        diff[i] = meanalt - meanref\n",
    "        maf[i] = float(len(ref)) / (len(ref) + len(alt))\n",
    "        n_alleles[i] = len(ref) + len(alt)\n",
    "        mean_major[i] = meanalt\n",
    "\n",
    "diff_df = diff_df = pd.DataFrame(data={'MajMinDiff':diff,\n",
    "                                       'MeanMajor': mean_major,\n",
    "                                       'MAF':maf,\n",
    "                                       'NAlleles':n_alleles})\n",
    "diff_df['SNP'] = mysnpdata.sid\n",
    "results_df = pd.merge(results_df, diff_df, on='SNP')\n",
    "\n",
    "\n",
    "\n",
    "# PHENOTYPE shuffling/permutation and adding the p-values from the resulting\n",
    "# GWAS to the results data frame.\n",
    "#phenotype_to_shuffle = pd.read_table(phenotype_data,\n",
    "#                                     sep=' ', header=None)\n",
    "#indices = range(len(phenotype_to_shuffle))\n",
    "#temp_shuffled_pheno = '../Outputs/Fast-Lmm-Inputs/Temporary-Shuffled-Phenotype.txt'\n",
    "#\n",
    "#for i in range(NUMBER_OF_PERMUTATIONS):\n",
    "#    time_permut_0 = time.time()\n",
    "#    shuffle(indices)\n",
    "#    phenotype_shuffled = []\n",
    "#    for j in range(len(indices)):\n",
    "#        phenotype_shuffled.append(phenotype_to_shuffle[2][indices[j]])\n",
    "#    \n",
    "#    phenotype_to_shuffle[2] = phenotype_shuffled\n",
    "#    phenotype_to_shuffle.to_csv(temp_shuffled_pheno, header=False, index=False, sep=' ')\n",
    "#    tmp_shuffled_df = single_snp(variants_to_test,  temp_shuffled_pheno,\n",
    "##                                cache_file='../Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache'+str(i)\n",
    "#                                 cache_file='../Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache.npz',\n",
    "#                                 leave_out_one_chrom=False,\n",
    "#                                 )\n",
    "#    tmp_shuffled_df['Full ID'] = tmp_shuffled_df['Chr'].astype('str') + '_' + tmp_shuffled_df['ChrPos'].astype('str')\n",
    "#    \n",
    "#    # sorting the new df to match the original\n",
    "#    tmp_shuffled_df = tmp_shuffled_df[['Full ID', 'PValue']]\n",
    "#    tmp_shuffled_df['PValue'].rename('PValueShuffled'+str(i+1))\n",
    "#    \n",
    "#    \n",
    "#    results_df = pd.merge(results_df, tmp_shuffled_df, on='Full ID')\n",
    "#    print('Time for permutation GWAS:' + str(time.time() - time_permut_0) + 's')\n",
    "    \n",
    "\n",
    "# Shuffling ALLELES by VARIANT\n",
    "\n",
    "for i in range(NUMBER_OF_PERMUTATIONS):\n",
    "    time_permut_0 = time.time()\n",
    "    \n",
    "    # Python works a little different than R: Shuffle directly modifies the input data frame!\n",
    "    np.random.shuffle(mysnpdata.val)\n",
    "    Bed.write('VariantsPermuted', mysnpdata)\n",
    "    copyfile(variants_to_test + '.bim', 'VariantsPermuted.bim')\n",
    "\n",
    "    tmp_shuffled_df = single_snp('VariantsPermuted',  phenotype_data,\n",
    "#                                cache_file='../Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache'+str(i)\n",
    "                                 cache_file='../Outputs/Fast-Lmm-Cache/Gwas-Permutations-Cache.npz',\n",
    "                                 leave_out_one_chrom=False,\n",
    "                                 )\n",
    "    tmp_shuffled_df['Full ID'] = tmp_shuffled_df['Chr'].astype('str') + '_' + tmp_shuffled_df['ChrPos'].astype('str')\n",
    "    \n",
    "    # sorting the new df to match the original\n",
    "    tmp_shuffled_df = tmp_shuffled_df[['Full ID', 'SNP', 'PValue']]\n",
    "    tmp_shuffled_df = tmp_shuffled_df.rename(columns={'Full ID':'Full IDShuffled'+str(i+1),\n",
    "                                                      'PValue':'PValueShuffled'+str(i+1)})\n",
    "    \n",
    "    snpdata = mysnpdata.val\n",
    "    diff = range(snpdata.shape[1])\n",
    "    maf = range(snpdata.shape[1])\n",
    "    n_alleles = range(snpdata.shape[1])\n",
    "    mean_major = range(snpdata.shape[1])\n",
    "    for k in range(snpdata.shape[1]):\n",
    "        ref = [j for j, x in enumerate(snpdata[:,k]) if x == 2]\n",
    "        alt = [j for j, x in enumerate(snpdata[:,k]) if x == 0]\n",
    "        meanref = np.mean(pheno[ref])\n",
    "        meanalt = np.mean(pheno[alt])\n",
    "        if len(ref) > len(alt):\n",
    "            diff[k] = meanref - meanalt\n",
    "            maf[k] = float(len(alt)) / (len(ref) + len(alt))\n",
    "            n_alleles[k] = len(ref) + len(alt)\n",
    "            mean_major[k] = meanref\n",
    "        elif len(ref) + len(alt) == 0:\n",
    "            diff[k] = float('NaN')\n",
    "            maf[k] = float('NaN')\n",
    "            n_alleles[k] = len(ref) + len(alt)\n",
    "            mean_major[k] = float('NaN')\n",
    "        else:\n",
    "            diff[k] = meanalt - meanref\n",
    "            maf[k] = float(len(ref)) / (len(ref) + len(alt))\n",
    "            n_alleles[k] = len(ref) + len(alt)\n",
    "            mean_major[k] = meanalt\n",
    "        \n",
    "    diff_df = diff_df = pd.DataFrame(data={'MajMinDiffShuffled'+str(i+1):diff,\n",
    "                                           'MeanMajorShuffled'+str(i+1): mean_major,\n",
    "                                           'NAllelesShuffled'+str(i+1):n_alleles,\n",
    "                                           'MAFShuffled'+str(i+1):maf})\n",
    "    diff_df['SNP'] = mysnpdata.sid\n",
    "    tmp_shuffled_df = pd.merge(tmp_shuffled_df, diff_df, on='SNP')\n",
    "    tmp_shuffled_df = tmp_shuffled_df.rename(columns={'SNP':'SNPShuffled'+str(i+1)})\n",
    "    \n",
    "#    results_df = pd.merge(results_df, tmp_shuffled_df, on='Full ID')\n",
    "    results_df = results_df.join(tmp_shuffled_df)\n",
    "    print('Time for permutation GWAS:' + str(time.time() - time_permut_0) + 's')    \n",
    "\n",
    "\n",
    "results_df.to_csv(OUTPUT_NAME + '-with-Permutations.txt', sep=\"\\t\", index=False)\n",
    "\n",
    "\n",
    "#os.chdir('Desktop/MastersProject/Fast-Lmm')\n",
    "#\n",
    "#\n",
    "#    \n",
    "## Finally, plotting doing a Manhattan and QQ plot to visualize significant variants...\n",
    "#import pylab\n",
    "#import fastlmm.util.util as flutil\n",
    "#flutil.manhattan_plot(results_df.as_matrix([\"Chr\", \"ChrPos\", \"PValue\"]),pvalue_line=1e-5,xaxis_unit_bp=False, plot_threshold=0.0001)\n",
    "#pylab.show()\n",
    "#\n",
    "#from fastlmm.util.stats import plotp\n",
    "#plotp.qqplot(results_df[\"PValue\"].values, xlim=[0,5], ylim=[0,5])\n",
    "#\n",
    "#OUTPUT_NAME = '../Outputs/Fast-Lmm-Outputs/Food-Intake-Male'\n",
    "#results_df = pd.read_csv(OUTPUT_NAME + '-Original.txt', sep='\\t')\n",
    "#    \n",
    "## Finally, plotting doing a Manhattan and QQ plot to visualize significant variants...\n",
    "#import pylab\n",
    "#import fastlmm.util.util as flutil\n",
    "#flutil.manhattan_plot(results_df.as_matrix([\"Chr\", \"ChrPos\", \"PValue\"]),pvalue_line=1e-5,xaxis_unit_bp=False, plot_threshold=0.0001)\n",
    "#pylab.show()\n",
    "#\n",
    "#from fastlmm.util.stats import plotp\n",
    "#plotp.qqplot(results_df[\"PValue\"].values, xlim=[0,5], ylim=[0,5])\n",
    "#\n",
    "#OUTPUT_NAME = '../Outputs/Fast-Lmm-Outputs/Food-Intake-Dimorphism'\n",
    "#results_df = pd.read_csv(OUTPUT_NAME + '-Original.txt', sep='\\t')\n",
    "#    \n",
    "## Finally, plotting doing a Manhattan and QQ plot to visualize significant variants...\n",
    "#import pylab\n",
    "#import fastlmm.util.util as flutil\n",
    "#flutil.manhattan_plot(results_df.as_matrix([\"Chr\", \"ChrPos\", \"PValue\"]),pvalue_line=1e-5,xaxis_unit_bp=False, plot_threshold=0.0001)\n",
    "#pylab.show()\n",
    "#\n",
    "#from fastlmm.util.stats import plotp\n",
    "#plotp.qqplot(results_df[\"PValue\"].values, xlim=[0,5], ylim=[0,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
